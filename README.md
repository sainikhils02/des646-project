# AI-Powered Design Assistant

The **AI-Powered Design Assistant** is a comprehensive tool designed to evaluate digital designs for **fairness**, **accessibility**, and **ethical user experience**. Built with **Python** and **Streamlit**, it performs automated audits on either live web pages (via URL) or uploaded screenshots, generating a holistic **Design Fairness Score** that reflects accessibility compliance, visual contrast, and ethical UX patterns.

---

## ğŸš€ Key Features

- **Multi-Modal Input:** Analyze designs from a live **URL** or a **screenshot** (PNG/JPG).
- **Accessibility Auditing:** Performs WCAG compliance checks using the `axe-core` engine through Selenium.
- **Contrast Analysis:** Uses OpenCV-based heuristics to detect low-contrast text and UI regions.
- **Ethical UX Scoring:** Identifies manipulative â€œdark patternsâ€ using a Transformer-based NLP model (Hugging Face or custom fine-tuned).
- **AI-Enhanced Analysis:** Optionally integrates **Google Gemini** for multimodal validation and natural-language audit insights.
- **Interactive Dashboard:** Streamlit interface with Plotly visualizations for real-time exploration of audit results and trends.
- **Comprehensive Reporting:** Generates structured reports in **Markdown**, **PDF**, and **JSON** formats.
- **Audit History:** Saves all audits for historical analysis, comparison, and progress tracking.
- **Configurable Pipeline:** Modular architecture allows customization of thresholds and scoring weights.

---

## ğŸ§  Technology Stack

| Layer | Tools & Libraries |
|-------|-------------------|
| **Frontend** | Streamlit, Plotly |
| **Auditing** | Selenium, axe-core, OpenCV |
| **AI/NLP** | Google Gemini (optional), Hugging Face Transformers |
| **Reporting** | Markdown, ReportLab (PDF), JSON |
| **Language** | Python 3.8+ |

---

## âš™ï¸ Installation & Setup

### 1. Clone the repository
```bash
git clone https://github.com/sainikhils02/des646-project.git
cd des646-project
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate    # macOS/Linux
# venv\Scripts\activate     # Windows
```

### 3. Install dependencies
If you already have a `requirements.txt` file:
```bash
pip install -r requirements.txt
```

If not, create one with:
```
streamlit
pandas
plotly
axe-selenium-python
opencv-python
transformers
reportlab
selenium
```

Then run:
```bash
pip install -r requirements.txt
```

### 4. (Optional) Enable Gemini AI Integration
To enable Google Gemini-based AI analysis:

1. Get an API key from [Google AI Studio](https://aistudio.google.com/apikey)
2. Set it as an environment variable:

```bash
# macOS/Linux
export GOOGLE_API_KEY="YOUR_API_KEY"

# Windows PowerShell
$env:GOOGLE_API_KEY="YOUR_API_KEY"
```

---

## ğŸ’» Running the Application

### Option 1 â€“ Streamlit Dashboard
```bash
streamlit run app.py
```

This opens the interactive web UI in your browser.

**Dashboard sections:**
1. **Home** â€“ Overview of the toolâ€™s features.  
2. **Audit** â€“ Input URL or screenshot, adjust weights, and run the audit.  
3. **Reports** â€“ Visual summaries (radar/gauge charts, tables, scores).  
4. **History** â€“ Explore or delete past audits.  
5. **About** â€“ Details on methods and technologies used.

### Option 2 â€“ Command-Line Interface
Run directly from CLI:
```bash
python -m design_assistant <mode> <value> [--output-dir <path>]
```

**Examples:**
```bash
python -m design_assistant url https://example.com --output-dir audits/
python -m design_assistant screenshot ./design.png
```

---

## ğŸ§© Project Structure

```
des646-project/
â”‚
â”œâ”€â”€ app.py                          # Streamlit app entry point
â”œâ”€â”€ design_assistant/
â”‚   â”œâ”€â”€ pipeline.py                 # Core orchestration logic
â”‚   â”œâ”€â”€ fusion.py                   # Score computation logic
â”‚   â”œâ”€â”€ reporting.py                # JSON / MD / PDF writers
â”‚   â”œâ”€â”€ llm_integration.py          # Gemini model integration
â”‚   â”œâ”€â”€ audits/
â”‚   â”‚   â”œâ”€â”€ accessibility.py        # axe-core wrapper
â”‚   â”‚   â”œâ”€â”€ contrast.py             # OpenCV contrast analysis
â”‚   â”‚   â”œâ”€â”€ dark_patterns.py        # NLP-based dark pattern detection
â”‚   â”œâ”€â”€ collectors/
â”‚   â”‚   â”œâ”€â”€ selenium_collector.py   # DOM + Screenshot from URLs
â”‚   â”‚   â”œâ”€â”€ screenshot_loader.py    # Local image ingestion
â”‚   â””â”€â”€ ...
â”œâ”€â”€ outputs/                        # Generated reports and JSONs
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ fine_tune_dark_patterns.py  # Model fine-tuning utility
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Fine-Tuning the Dark Pattern Model

You can fine-tune your own Transformer-based model for dark pattern classification:

```bash
python scripts/fine_tune_dark_patterns.py   /path/to/train.csv   /path/to/val.csv   --model "distilbert-base-uncased"   --output-dir "custom-dark-pattern-model"
```

The CSVs must include:
- `text` â€” UI text content
- `label` â€” dark pattern category (e.g., *Urgency*, *Confirm-shaming*)

Once trained, you can plug the model into the pipeline via the `DarkPatternAuditor`.

---

## âš™ï¸ Configuration Options

| Config Area | Description |
|--------------|--------------|
| **Environment Variables** | API keys, service credentials, etc. |
| **Audit Thresholds** | WCAG contrast ratios, dark-pattern confidence cutoffs |
| **Weight Parameters** | Î± (Accessibility) and Î² (Ethical UX) coefficients |
| **Reports** | Output format and save directory |
| **Session Persistence** | Enables saving historical audits to local storage |

---

## ğŸ¤ Contributing

We welcome contributions to improve this tool!  
To contribute:

1. Fork this repository  
2. Create a new feature branch  
3. Commit your changes with clear messages  
4. Submit a Pull Request to `main`

**Guidelines:**
- Follow existing code style  
- Add comments for complex logic  
- Test thoroughly before submitting  

---

## ğŸ“š Acknowledgments

- [Streamlit](https://streamlit.io/) â€“ Web framework  
- [axe-core](https://www.deque.com/axe/) â€“ Accessibility engine  
- [Plotly](https://plotly.com/) â€“ Data visualization  
- [Google Gemini](https://aistudio.google.com/) â€“ Multimodal AI model  
- [Hugging Face Transformers](https://huggingface.co/) â€“ NLP models  
- [OpenCV](https://opencv.org/) â€“ Image processing  
- [ReportLab](https://www.reportlab.com/) â€“ PDF generation  

---

## ğŸ“ˆ Future Work & TRL Roadmap

Our current implementation demonstrates a **functional prototype (TRL-4)**, validated as a proof of concept through live audits and reporting.  
To progress to **TRL-5**, we aim for systematic validation in simulated environments and acceptance testing.  
Further progress to **TRL-6+** will involve extended trials, deployment in production environments, and collaboration with UX and accessibility experts for real-world validation.
